# FILE DATA
ID : SDRW2100002448
category :  구어 > 사적대화 > 협력적대화

# DOCUMENT DATA
title : 3인 일상 대화
author : 개인 발화자
publisher : 개인 발화 녹음
date : 20220118
topic : AI의 직업 대체 > 찬: 기술혁신 발전하고 있는데 거기서 막으면 안 좋다

# SPEAKER_INFO
id : SD2102059
age : 10대
occupation : 학생
sex : 여성
birthplace : 경기
principal_residence : 경기
current_residence : 경기
education : 대재

id : SD2102060
age : 10대
occupation : 학생
sex : 여성
birthplace : 경기
principal_residence : 경기
current_residence : 경기
education : 대재

id : SD2102061
age : 20대
occupation : 학생
sex : 여성
birthplace : 경기
principal_residence : 경기
current_residence : 경기
education : 대재

# SETTING
relation  :  친구


P1 	:일단 나는 / 에이아이에 직업 대체에 대해서 찬성하는 바야. /
	 왜냐면 이제 / 사실 지금 기술 혁신이 계속해서 이루어지고 있고 사 차 산업혁명이 이루어지고 있어 / 근데 에이아이 직업 대체를 막는다? /
	 그럼 이건 기술 혁신과 지금에 기술 발전을 막는 것과 같다 생각해 / 거기다가 이제 에이아이가 만약에 이렇게 더 활용화돼 가지고 우리 직업군에 이렇게 들어오게 된다면은 / 이제 고효율 저비용적으로 이렇게 사용을 할 수 있는 거야 / 그 돈이 덜 드는 거지 효율은 계속 나는데 / 그리고 이제 이런 걸로 / 예시를 들자면은 / 우리가 지금 사용하는 이제 홈쇼핑이나 그런 사이트들을 들어갈 때 챗봇 같은 게 있잖아? /
	 그게 다 인공지능으로 이루어진 거거든. /
	 그것처럼 이렇게 좋게 활용되는 예시가 있는 거 같아. /
	
P2 	:나는 반대해 / 일딴 에이아이가 모든 직업들을 대체하기 시작하면 / 그 대체한 직업들이 사라지면서 실업난이 생길 꺼야 / 그리고 구직에 대해서 어려워질 꺼야 인공지능이 발달했기 때문에 / 그 직업을 인공지능이 대체하기 때문에 / 그리고 나이 드신 분들이나 인터넷이 어려운 사람들은 / 그 새로운 일자리에 맞춰 가기도 더 힘들어지겠지? /
	 그리고 에이아이가 결정을 내리거나 그 / 뭔가 결정을 내릴 때 인간이 그걸 이해할 수 있을까? /
	 그 문제도 있는 거 같애. /
	
P0 	:어 나도 에이아이가 우리에 직업을 대체하는 것에 대해 반대를 하는데 / 아까 너가 / 이 발전을 막는다라는 표현을 썼는데 사실 나는 발전을 막는다라고 생각하지 -않- 않아 / 이게 직업을 대체하면 안 된다는 말이지 / 에이아이를 아예 사용하지 말자라는 말이 아니거든. /
	 그래서 우리가 일을 할 때 컴퓨터를 활용하는 것처럼 / 에이아이를 사람이 활용해야 하는 면으로 가야 된다고 생각하 생각을 하고 / 내가 아까 챗봇을 말했는데 사실 챗봇 나도 사용을 해 봤거든 / 근데 나는 / 쫌 불편해서 그냥 차라리 전화를 하게 되더라고 /
	
P1 	:이제 / 하 사용을 말자가 아니라고 했는데 이제 / 이게 사실 우리가 사용을 안 하고 그냥 혼자서 기술 개발만 이루어지게 되면은 이거는 기술에 발전 자체가 더뎌질 수밖에 없어. /
	 왜냐면 우리가 이렇게 활용하고 니가 아까 전에 / 챗봇 사용해 봤는데 불편하다고 했잖아? /
	 근데 그런 불편함을 깨닫고서 / 더 빅데이터를 가지고서 이렇게 계속해서 교육을 시키면은 / 이제 그게 또 발전에 그런 계기가 되는 거지 / 그리고 이제 사람이 활용하는 면은 괜찮다고 했는데 지금 우리가 이렇게 / 직업적으로 그리고 공장에서 돌리는 기계같이 활용하는 거 자체가 우리가 에이아이를 활용하는 거라 생각해 / 그리고 이제 실업난이나 구직 그리고 새로운 일자리 / 를 이제 얻기 힘들다고 했는데 그래서 나는 이게 로봇세를 부과해야 된다고 생각해. /
	
P2 	:어 에이아이가 아무리 뛰어나도 인간과 동등한 사고를 할 수 있나? /
	 공 / 공감을 할 수 있나 그게 불가능하다고 봐 / 그래서 윤리적인 문제도 발생할 수 있고 기계이다 보니까 오류를 일으킬 수도 있고 / 어 그리고 에이아이에게 / 인류가 멸망한다는 소리도 있잖아 그 / 스티븐 호킹에 에이아이 경고라고 / 에이아이가 인간을 대체하는 날 / 에이아이 때문에 인류가 멸종이 올 수도 있다는 말도 / 영화처럼 실제로 일어날 수 있는 일이라고 봐. /
	
P0 	:나도 그렇게 생각하고 / 아까 나도 에이아이에 발전을 막을 수 없다고 생각하고 발전도 해야 한다고 생각을 해 / 그리구 / 나는 그 활용하는 면이 직업을 대체하지 않고 인간이 / 인간이 걔를 활용하는 면으로 도구적인 면으로 다가가고 싶은 거였지 / 이 에이아이가 사람을 아예 대체해서 사용을 하면 안 된다고 생각했고 / 왜냐면 우리 일자리가 없어지니까. /
	 어쨌든 우리 편하자고 에이아이를 만든 건데 / 어떻게 되면 일자리를 잃고 생곌 유지하기 어려워지는 것까지 가게 되니까 / 에이아이가 그렇게까지 대체하게 되고 / 하게 되면은 힘들지 않을까라고 생각을 했어. /
	
P1 	:이제 방금 같은 말 같은 거는 이제 롯떼만 해도 과자 만드는 거 포장하는 거는 다 기계가 하고 있잖아? /
	 근데 이제 / 걔네가 못 하는 세부적인 빡스 포장 작업이나 그런 것만 인간들이 하는 거지 / 이미 그거 가지고 / 이미 나는 일자리 대체가 시작됐다고 생각해. /
	 그래서 / 그래 아까 전에 에이아이는 인간과 똑같을 수 없다 했는데 맞아. /
	 에이아이는 인간과 절대 똑같을 수 없어. /
	 감정을 가지지 않았기 때문에 / 감정을 학습 시키는 거지 절대 얘네는 감정을 가질 수 없 / 고 에이아이 인류 멸망에 대해서 말했는데 / 에이아이 인류 멸망은 이제 에이아이가 / 이제 지배적인 그런 생각을 가지고 있어야 돼 / 근데 이 지배 요건이 / 일 번이 자기 자신을 인식하고 지개 지배 욕망을 가질 껏 그리고 인간에게 적대감을 가져야 되는데 / 이 시스템상 절대 이렇게 될 수 있어 / 될 수 없어. /
	 이렇게 되는 건 이제 원숭이가 타자기를 쳐 가지고 셰익스피어를 만들어 내는 거래 확률이. /
	
P2 	:응 그리고 인공지능 시스템에 악용 / 그 뭐지 / 어 범죄에 사용될 수도 있고 / 해킹 / 이런 문제도 나올 수도 있고 / 그리고 -테슬- 테슬라 아 자동화 / 자동차로 / 잘못된 인식으로 인해서 사고가 나서 사람이 사망한 사례도 있거든. /
	 그래서 에이아이에 대체는 위험하다고 봐. /
	
P0 	:네 어 그래서 어 / 그치 / 인류가 멸망하지 않는다고 했고 원숭이가 타자기를 쳐서 셰익스피어를 만들어 내는 거라고 말을 했는데 / 근데 우리가 / 상상한 대로 될까라는 생각한 대로 될까라는 생각이 들어 나는 / 이게 / 학습을 하잖아? 그래서 우리 사실 예술 영역까지도 뛰어넘을 수 있다고 하거 하다고 하더라고 / 약간 그런 걸 표현할 수 있다고 해서 / 난 그 에이아이가 어떻게 발전을 하고 어디까지 가는지를 -사람- 사람이 가늠할 수 있을까라는 생각이 들기도 해 / 사람은 어쨌든 뛰어넘었고 / 또 사람을 대체해서까지 사용해서 더 좋 / 으니까 더 편리하고 더 정확하니까 / 그래서 어디까지 갈 수 있을지를 / 과연 함부로 예측할 수 있는 것일까라는 생각이 들어. /
	
P1 	:사실 에이아이가 우리보다 더 잘 배우고 더 뛰어난 건 맞아. /
	 근데 그렇다고 해서 내가 이제 / 지배를 못 한다는 거는 / 우리가 우리 감정이 어떻게 있는지 내가 저걸 좋아하는데 그 이유가 뭔지 정확하게 설명할 수 없어. /
	 우리도 모르는 걸 에이아이가 / 학습할 수 있다. /
	 왜냐면 감정은 그 사람을 나타내는 개개인 고유에 성향 같은 거잖아? /
	 에이아이는 시스템화고 / 그게 시스템상으로 이제 말이 될 수 없다고 생각해 나는 / 그래 가지고 이제 아까 말했듯이 이제 범죄나 해킹에 대해서 얘기했는데 / 오히려 에이아이가 범죄나 해킹 같은 데 도움이 될 수도 있다 생각해 / 얼굴 인식 가지고 이제 씨씨 티비를 사람이 다 보지도 않고 / 이제 얼굴 인식만 가지고서 / 빅데이터를 가지고 / 이제 그걸 가지고서 이제 씨씨 티비에 그 범죄자가 어디 어디 어디에 나타났었는지 그걸 볼 수도 있고 / 오히려 범죄 예방 쪽으로도 도움이 될 수도 있다고 생각해. /
	
P2 	:에이아이가 윤리적인 문제도 있거든 / 인공지능이 운전을 하다가 사고가 났어 / 그 과실은 / 누가 물어야 하는지 / 내가 운전을 하지 않고 인공지능이 운전을 해 왔기 때문에 / 그런 윤리적 문제도 발생하고 / 그리고 인공지능 이런 것들을 연구 개발하는 회사가 / 독점 / 그 / 발전하고 / 뭔가 만들어 내는 데 독점이 / 독점 체제가 강화되므로 / 여기서 건 경제적 이익이나 이런 것들을 다 가져갈 수 있다고 / 우려가 돼. /
	
P0 	:그리고 이제 범죄 해킹이 된다고 했는데 오히려 / 범죄 그런 해킹을 잡는 데도 도움이 될 수 있다고 말했잖아? /
	 근데 나는 그 도움이 되는 것만큼 더 큰 문제가 있을 꺼라고 생각하거든. /
	 양날에 검이 있잖아? /
	 그래서 또 이제 다이너마트 다이너마이트를 만든 사람도 / 그렇게 범 그 전쟁에 사용될 줄 알고 그 사람은 다이너마이트를 만든 게 아니잖아? /
	 그것처럼 인공지능도 그만큼 편한 만큼 / 또 굉장한 큰 문제점을 또 같이 가져올 꺼라고 생각해. /
	
P1 	:근데 나는 이제 이게 기술 발전을 통해서 어떻게든 거쳐 가야 될 입장이라고 생각해 / 지금 늦춘다고 해서 절대 안 거쳐 갈 껀 아니니까 / 그 인공지능 사고 책임에 대해서 말했는데 근데 이거 같은 경우는 이제 외국에서 이미 우리나라도 시행하고 있는 닥터 왓슨이란 게 있어 / 사람을 / 에이아이가 진단을 하는 거야. /
	 근데 / 근데 이게 암 발견도가 오십 퍼센트에서 구십 퍼센트까지 올라갔어 / 그럼 사람들한테 좋은 거지 근데 대신에 총책임자는 의사야 / 에이아이가 의사한테 도움을 주는 거지 / 미리 다 진단해 놓고 이거에 대해서 이렇게 처방을 내려도 될까요? /
	 이렇게 도움이 될 수가 있는 거야 / 그리고 회사에 이익 독점이라 했는데 그래서 나는 / 아까와 같이 로봇세를 부과해야 된다 생각하는 거야. /
	 이제 그 로봇을 가지고 만든 이익을 가지고 로봇세를 부과해서 그거를 이제. /
	 미에 밑에 사람들한테 도움을 줘서 재취업에 그런 돕 기회 교육을 주는 거지. /
	
P2 	:의사가 책임을 진다 그랬는데 에이아이를 사용함으로써 / 근데 자동차 운전에는 / 쪼끔 다른 / 거 같아 자동차 운전은 / 내가 이 차를 돈을 주고 구매를 해서 / 했는데 회사에서 지원해 주는 기능이야 / 그 기능을 사용하다가 / 사고가 난 걸 / 과연 / 그 운전하는 사람이 돈을 지불하고 그 기능을 얻었는데 / 그걸 자기 책임으로 생각을 할지 / 회사에 소송을 걸거나 / 이의를 제기할지 / 궁금해. /
	
P0 	:응 그치 / 그래서 / 지금 가장 큰 문제점은 / 우리가 편하자고 또 더 좋은 세상을 만들기 위해서 에이아이를 만들었는데 / 그것들이 사람들에 일자리를 / 차지하고 또 사람들은 생계를 잃어 가는 것이 가장 큰 문제점이잖아? /
	 그래서 지금 현재도 노령 빈곤이 되게 심각한 문제인데 / 그런데 그런 / 노령자분들이 할 수 있는 직업들을 대부분 다 에이아이가 할 수 있잖아? /
	 또 단순 노동 / 노동직도 인제 에이아이가 대체할 수 있고 / 근데 그렇게 해서 더 빠르게 더 정확하게 할 수 있음 나도 에이아이를 쓰겠지. /
	 하지만 그 사람들의 생계는 누가 책임져 줄 껏이며 / 약간 그런 기반들이 / 먼저 돼야 된다고 하거든 생 / 먼저 되어야 된다고 생각해 에이아이가 발전하기 이전에. /
	
P1 	:어 일딴 아까 전에 이제 사고에 대해서 얘기했는데 만약에 그게 / 그냥 사고가 났다라고 말해서 그런데 그냥 사고가 나면 그건 / 기계적 결함이지 왜 갑 / 짜기 이제 사고가 날 리가 없잖아? /
	 만약에 / 장애물이 두 개가 있는데 둘 중에 어느 쪽으로 피해서 사고가 났다 그럼 둘 다 사고가 어차피 날 운명이었기 / 때문에 나는 그건 상관이 없고 만약에 그냥 사고가 났으면 그건 기계적 오류기 때문에 당연히 회사 책임이라고 -생- -생- 생각해 / 물론 산 사람은 책임이 없고 / 그리고 / 이제 아까 전에 그런 / 어 노인들이나 그런 거에 대해서 얘기했었는데 그래서 나는 기본소득도 같이 부과해야 된다 생각해 / 우리 아까 전에 로봇세를 걷자고 했잖아? /
	 그 로봇세를 가지고 / 이제 교육도 시키는데 / 기본 근데 그렇게 되면 이제 자본주의 체계가 붕괴될 수 있으므로 기본소득을 줘 가지고 어느 정도에 총수요를 이제 다시 / 이렇게 사 갈 수 있는 / 그런 이제 순환이 될 수 있다고 생각해 나는 그러면은. /
	
P2 	:에이아이가 똑똑하고 / 인간에 기능을 / 뛰어넘잖아? /
	 그러면서 그 에이아이가 / 인간에 통제를 뛰어넘고 / 어 / 멋대로 작동이 되거나 진짜 영화와 같은 일이 발생되면 / 정말 인류에 엄청나게 큰 문제가 발생하는 거잖아? /
	 우리에 계속되는 이익을 추구하다가 / 멸망까지 올 수도 있다고 봐. /
	
P0 	:그치 그럴 수도 있지 / 근데 지금도 사실은 실업 문제가 많 / 언니 있잖아 / 근데 그것도 지금 해결도 못 하고 있는데 / 또 에이아이까지 너무 발전이 빠르게 와서 / 이것까지 문제 해결을 못 해 / 그럼 나는 약간 이건 큰 문제라고 생각하거든 에이아이가 대체하는 것에. /
	 나도 너무 편하고 좋으니까 나도 당연히 대체하고 싶지만 / 이거를 편하고 좋다고 해서 바로 대체해 버리면 문제쩜을 / 해결을 하지 못하니까 /
	
P1 	:어 아까도 이제 그 지구 멸망 같은 걸 얘기했는데 그거는 이제 시스템적으로조차 불가능한 게 / 감정은 인간만이 가지고 있는 거고 이거를 우리가 / 교육을 시킬 수 있어 만약에 이런 상황이 슬프다 하지만은 어떤 사람은 이런 상황에 안 슬플 수도 있어 / 그걸 가지고 에이아이한테 이런 상황엔 슬퍼하고 빅데이터적으로 그거를 수집하는 거지. /
	 그거를 걔가 갖고 있는 게 아니야 / 그거는 정보를 가지고 있는 거지. /
	 정보를 가진다와 스스로 생각한다에 차이는 매우 다르거든 / 그래서 걔네가 스스로 생각한다? /
	 이게 그래서 아까 전에 말했던 게 / 이제 그게 그렇게 하는 거야. /
	 원숭이가 타자 쳐서 이제 셰익스피어 만들 확률이란 게 그런 거야. /
	 만약에 칩이 고장 나거나 그래도 절대 그럴 일이 없다는 게 /
	
P2 	:맞아 에이아이가 발전되면 / 진짜 인간이 하지 못하는 하기 싫어하는 그런 쓰리디 직업이라 하지 / 그런 것들을 에이아이에 대체되면 / 누가 하나 안 할려 하는 일도 / 에이아이로 대체되고 / 좋을 꺼 같애. /
	 그리고 또 대규모 작업 엄청 큰 작업들을 / 에이아이가 빨리빨리 처리하니까 비용도 절감되고 / 노동력도 감소 / 어 / 되니까 / 에이아이에 찬성해. /
	
P0 	:그치 / 이제 고효율 저비용이라고 했잖아? /
	 우리 / 한 사람 열 명이서 해야 하는 일을 이제 에이아이 하나로 / 해결할 수 있고 또 / 위험한 직업들도 약간 예를 들 예를 들면 소방관이나 뭐 / 창문 외관 딲는 사람들도 많이 떨어져서 돌아가시는데 / 그런 것도 에이아이가 대체해서 약간 사람에 목숨도 / 보호할 수 있는 그런 면을 가지고 있는 거 같아. /
	
P1 	:사실 이제 아까 전까지만 말했을 때 실업 사태가 사실 큰 이슈야 문제가 될 수도 있 / 문제가 되고 당연히 / 근데 이제 만약에 에이아이가 이렇게 직업을 대체하게 되면은 노동 생상성도 높아지고 일자리는 줄어들겠지 / 실업은 생기고 총수요가 부족하게 될 꺼야 이제. /
	 물건은 많은데 / 소비하는 사람이 없으니까 / 그래서 이렇게 되면 이제 자본주의 시스템이 멈춘다. /
	 근데 이렇게 되는데 사실 우리는 쫌 다르게 / 생각에 발상에 전환이 필요할 때인 거 같아 / 이제 / 우리는 그전까지 일하지 않는 자 먹지도 말라 노동에 신성함 이렇게 얘기했는데 그게 이제는 그게 아니라 / 우리가 이제 기본소득이나 그런 걸 추가적으로 얻고 더 다른 새로운 방향으로 / 교육을 제시함으로써 다른 방식으로 교육을 하고 / 오히려 인간만이 할 수 있는 / 인간만이 할 수 있는 일을 강화시키고 / 인공지능을 적극적으로 활용하는 방안으로써 더 활용할 수 있다고 생각해. /
